{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline \n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "sns.set_style(\"white\")\n",
    "sns.set_palette('husl')\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pickled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./clean_wine_data_w_target.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>province</th>\n",
       "      <th>variety</th>\n",
       "      <th>target</th>\n",
       "      <th>target_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aroma include tropical fruit broom brimstone d...</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>White Blend from Sicily &amp; Sardinia</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delicate aroma recall white flower citrus pala...</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>White Blend from Sicily &amp; Sardinia</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pretty aroma yellow flower stone fruit lead no...</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>White Blend from Sicily &amp; Sardinia</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>part extend calanìca series grillo viognier bl...</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>White Blend from Sicily &amp; Sardinia</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>offer heady aroma honeysuckle white stone frui...</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>White Blend from Sicily &amp; Sardinia</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description           province  \\\n",
       "0  aroma include tropical fruit broom brimstone d...  Sicily & Sardinia   \n",
       "1  delicate aroma recall white flower citrus pala...  Sicily & Sardinia   \n",
       "2  pretty aroma yellow flower stone fruit lead no...  Sicily & Sardinia   \n",
       "3  part extend calanìca series grillo viognier bl...  Sicily & Sardinia   \n",
       "4  offer heady aroma honeysuckle white stone frui...  Sicily & Sardinia   \n",
       "\n",
       "       variety                              target  target_code  \n",
       "0  White Blend  White Blend from Sicily & Sardinia          305  \n",
       "1  White Blend  White Blend from Sicily & Sardinia          305  \n",
       "2  White Blend  White Blend from Sicily & Sardinia          305  \n",
       "3  White Blend  White Blend from Sicily & Sardinia          305  \n",
       "4  White Blend  White Blend from Sicily & Sardinia          305  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all documents\n",
    "corpus = list(df.description)\n",
    "corpus = ' '.join(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all words in joined_corpus\n",
    "tokens = [word for word in word_tokenize(corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial run to create Document-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aacacia</th>\n",
       "      <th>aand</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abacela</th>\n",
       "      <th>abacelas</th>\n",
       "      <th>abadal</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abate</th>\n",
       "      <th>...</th>\n",
       "      <th>élevé</th>\n",
       "      <th>élévage</th>\n",
       "      <th>émilion</th>\n",
       "      <th>émilions</th>\n",
       "      <th>étoile</th>\n",
       "      <th>über</th>\n",
       "      <th>überaromatic</th>\n",
       "      <th>überbest</th>\n",
       "      <th>ürzig</th>\n",
       "      <th>ürziger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22872 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aacacia  aand  aaron  ab  abacela  abacelas  abadal  abandon  abate  \\\n",
       "0   0        0     0      0   0        0         0       0        0      0   \n",
       "1   0        0     0      0   0        0         0       0        0      0   \n",
       "2   0        0     0      0   0        0         0       0        0      0   \n",
       "3   0        0     0      0   0        0         0       0        0      0   \n",
       "4   0        0     0      0   0        0         0       0        0      0   \n",
       "\n",
       "   ...  élevé  élévage  émilion  émilions  étoile  über  überaromatic  \\\n",
       "0  ...      0        0        0         0       0     0             0   \n",
       "1  ...      0        0        0         0       0     0             0   \n",
       "2  ...      0        0        0         0       0     0             0   \n",
       "3  ...      0        0        0         0       0     0             0   \n",
       "4  ...      0        0        0         0       0     0             0   \n",
       "\n",
       "   überbest  ürzig  ürziger  \n",
       "0         0      0        0  \n",
       "1         0      0        0  \n",
       "2         0      0        0  \n",
       "3         0      0        0  \n",
       "4         0      0        0  \n",
       "\n",
       "[5 rows x 22872 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a document-term matrix using CountVectorizer\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(df.description)\n",
    "\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = df.index\n",
    "data_dtm.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    " - Way too many features, need to reduce dimensions\n",
    " - Increase list of stop words to target:\n",
    "   - Domain stop words\n",
    "   - Words only used in one review\n",
    "   - Check size of matrix, then potentially remove other most-common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domain Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_stopwords = ['tannins', 'tannin', 'flavor', 'flavors', 'drink', \n",
    "                    'wine', 'finish', 'hint', 'fruit', \n",
    "                    'note', 'offer', 'aroma', 'style', \n",
    "                    'character', 'hint', 'nose', 'bit', 'drinkable', \n",
    "                    'palate', 'import', 'bottle', 'varieties', \n",
    "                    'year', 'years', 'scented', 'scents', 'wine', \n",
    "                    'finish', 'acidity', 'show', 'make', 'age', 'well', \n",
    "                    'give', 'touch', 'good', 'vineyard', 'feel', 'like', \n",
    "                    'come', 'fine', 'style', 'taste', 'also', 'still', \n",
    "                    'one', 'alongside']\n",
    "\n",
    "\n",
    "#Domain Stopwords\n",
    "#TANNINS FLAVORS\n",
    "#FLAVOR DRINK\n",
    "#WINE FINISH\n",
    "#HINTS FRUIT\n",
    "#NOTES OFFERS\n",
    "#AROMAS STYLE\n",
    "#CHARACTER HINT\n",
    "#BIT DRINKABLE\n",
    "#PALATE IMPORTED\n",
    "\n",
    "# Domain stopwords adapted from a research paper which used the same basic dataset:\n",
    "# Martinez, R., et al.; Grapevine: A Wine Prediction Algorithm Using Multi-dimensional Clustering Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least-Used Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency distribution of words in corpus\n",
    "fdist = FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8348"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of words used only once in corpus\n",
    "used_once = fdist.hapaxes()\n",
    "len(used_once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edèlmio', 'cefalù', 'baccante', 'setback', 'alastro']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_once[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new stop words\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(domain_stopwords, used_once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8685"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This stop words list should cut down on original 30,526-word vocabulary!\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Used Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wine', 67170),\n",
       " ('flavor', 58056),\n",
       " ('fruit', 53925),\n",
       " ('aroma', 32911),\n",
       " ('finish', 31397),\n",
       " ('palate', 30902),\n",
       " ('acidity', 29657),\n",
       " ('drink', 29443),\n",
       " ('cherry', 28976),\n",
       " ('tannin', 28968),\n",
       " ('black', 25162),\n",
       " ('ripe', 23822),\n",
       " ('dry', 23102),\n",
       " ('note', 19936),\n",
       " ('spice', 19698),\n",
       " ('red', 18083),\n",
       " ('show', 16523),\n",
       " ('berry', 15946),\n",
       " ('oak', 15677),\n",
       " ('rich', 15298),\n",
       " ('fresh', 13949),\n",
       " ('offer', 13635),\n",
       " ('full', 13608),\n",
       " ('blackberry', 13304),\n",
       " ('nose', 13270),\n",
       " ('plum', 13155),\n",
       " ('balance', 12666),\n",
       " ('age', 12640),\n",
       " ('body', 12339),\n",
       " ('apple', 12209),\n",
       " ('blend', 11916),\n",
       " ('make', 11636),\n",
       " ('structure', 11523),\n",
       " ('well', 11518),\n",
       " ('soft', 11380),\n",
       " ('sweet', 11197),\n",
       " ('texture', 10877),\n",
       " ('dark', 10742),\n",
       " ('crisp', 10647),\n",
       " ('light', 10534),\n",
       " ('give', 10502),\n",
       " ('white', 10131),\n",
       " ('cabernet', 9518),\n",
       " ('raspberry', 9479),\n",
       " ('herb', 9389),\n",
       " ('vanilla', 9330),\n",
       " ('hint', 9109),\n",
       " ('year', 9102),\n",
       " ('bright', 9019),\n",
       " ('citrus', 8939),\n",
       " ('pepper', 8672),\n",
       " ('touch', 8562),\n",
       " ('firm', 8393),\n",
       " ('juicy', 8388),\n",
       " ('fruity', 8115),\n",
       " ('good', 8049),\n",
       " ('lemon', 7952),\n",
       " ('vineyard', 7780),\n",
       " ('currant', 7742),\n",
       " ('green', 7683),\n",
       " ('peach', 7602),\n",
       " ('chocolate', 7513),\n",
       " ('toast', 7361),\n",
       " ('pear', 7310),\n",
       " ('feel', 7115),\n",
       " ('character', 6979),\n",
       " ('open', 6978),\n",
       " ('like', 6847),\n",
       " ('come', 6695),\n",
       " ('bottle', 6374),\n",
       " ('fine', 6331),\n",
       " ('sauvignon', 6245),\n",
       " ('smooth', 6224),\n",
       " ('wood', 6079),\n",
       " ('mineral', 6033),\n",
       " ('pinot', 6031),\n",
       " ('spicy', 5988),\n",
       " ('style', 5951),\n",
       " ('taste', 5812),\n",
       " ('concentrate', 5645),\n",
       " ('lead', 5634),\n",
       " ('tannic', 5576),\n",
       " ('bite', 5555),\n",
       " ('round', 5501),\n",
       " ('licorice', 5443),\n",
       " ('also', 5390),\n",
       " ('lime', 5274),\n",
       " ('merlot', 5236),\n",
       " ('still', 5224),\n",
       " ('long', 5186),\n",
       " ('tart', 5178),\n",
       " ('layer', 5116),\n",
       " ('bake', 5114),\n",
       " ('medium', 5099),\n",
       " ('mouth', 4975),\n",
       " ('one', 4876),\n",
       " ('orange', 4861),\n",
       " ('dense', 4765),\n",
       " ('herbal', 4764),\n",
       " ('alongside', 4758)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find most commonly-used RELEVANT words (those not in domain_stopwords)\n",
    "\n",
    "fdist.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['amaro', 'argues', 'argument', 'assertive', 'bad', 'black', 'blend', 'block', 'buster', 'canaiolo', 'ciel', 'comb', 'comes', 'day', 'defined', 'dominates', 'edre', 'elements', 'especially', 'essential', 'ful', 'gentle', 'grained', 'graphite', 'grenache', 'honey', 'kiona', 'molasses', 'monte', 'mourv', 'oak', 'papery', 'power', 'prevail', 'prunes', 'pulciano', 'pushy', 'rhubarb', 'ripe', 'sand', 'sangiovese', 'sign', 'spice', 'spot', 'straightforward', 'structured', 'surprising', 'syrup', 'tea', 'university', 'worthiness', 'yang', 'ying', 'zinfandel'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aacacia</th>\n",
       "      <th>aaron</th>\n",
       "      <th>abacela</th>\n",
       "      <th>abadal</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abate</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>abeille</th>\n",
       "      <th>...</th>\n",
       "      <th>zweigelt</th>\n",
       "      <th>zédé</th>\n",
       "      <th>àmaurice</th>\n",
       "      <th>élevage</th>\n",
       "      <th>élevé</th>\n",
       "      <th>élévage</th>\n",
       "      <th>émilion</th>\n",
       "      <th>émilions</th>\n",
       "      <th>über</th>\n",
       "      <th>ürziger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aacacia  aaron  abacela  abadal  abandon  abate  abbey  abbott  abbreviate  \\\n",
       "0        0      0        0       0        0      0      0       0           0   \n",
       "1        0      0        0       0        0      0      0       0           0   \n",
       "2        0      0        0       0        0      0      0       0           0   \n",
       "3        0      0        0       0        0      0      0       0           0   \n",
       "4        0      0        0       0        0      0      0       0           0   \n",
       "\n",
       "   abeille  ...  zweigelt  zédé  àmaurice  élevage  élevé  élévage  émilion  \\\n",
       "0        0  ...         0     0         0        0      0        0        0   \n",
       "1        0  ...         0     0         0        0      0        0        0   \n",
       "2        0  ...         0     0         0        0      0        0        0   \n",
       "3        0  ...         0     0         0        0      0        0        0   \n",
       "4        0  ...         0     0         0        0      0        0        0   \n",
       "\n",
       "   émilions  über  ürziger  \n",
       "0         0     0        0  \n",
       "1         0     0        0  \n",
       "2         0     0        0  \n",
       "3         0     0        0  \n",
       "4         0     0        0  \n",
       "\n",
       "[5 rows x 14569 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a document-term matrix using CountVectorizer\n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "data_cv = cv.fit_transform(df.description)\n",
    "\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = df.index\n",
    "data_dtm.head()\n",
    "\n",
    "#Less features, still high (14,569)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-db2168b8bb14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtop_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtop_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   2824\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid na_position: {!r}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mna_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2826\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortedIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortedIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;31m# have a proper length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m                         raise ValueError(\n\u001b[1;32m    247\u001b[0m                             \u001b[0;34m'Length of passed values is {val}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Find the words used less than 2 times in descriptions\n",
    "top_dict = {}\n",
    "for c in data.columns:\n",
    "    top = data[c].sort_values(ascending=True).head(100)\n",
    "    top_dict[c]= list(zip(top.index, top.values))\n",
    "\n",
    "top_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top 15 words said by each comedian\n",
    "for comedian, top_words in top_dict.items():\n",
    "    print(comedian)\n",
    "    print(', '.join([word for word, count in top_words[0:14]]))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the least common words used (those used < 2 times) \n",
    "# --> add them to the stop word list\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Let's first pull out the top 30 words for each comedian\n",
    "words = []\n",
    "for comedian in data.columns:\n",
    "    top = [word for (word, count) in top_dict[comedian]]\n",
    "    for t in top:\n",
    "        words.append(t)\n",
    "        \n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's aggregate this list and identify the most common words along with how many routines they occur in\n",
    "Counter(words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If more than half of the comedians have it as a top word, exclude it from the list\n",
    "add_stop_words = [word for word, count in Counter(words).most_common() if count > 6]\n",
    "add_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list of tokenized descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aromas',\n",
       "  'include',\n",
       "  'tropical',\n",
       "  'fruit',\n",
       "  'broom',\n",
       "  'brimstone',\n",
       "  'and',\n",
       "  'dried',\n",
       "  'herb',\n",
       "  'the',\n",
       "  'palate',\n",
       "  'isnt',\n",
       "  'overly',\n",
       "  'expressive',\n",
       "  'offering',\n",
       "  'unripened',\n",
       "  'apple',\n",
       "  'citrus',\n",
       "  'and',\n",
       "  'dried',\n",
       "  'sage',\n",
       "  'alongside',\n",
       "  'brisk',\n",
       "  'acidity'],\n",
       " ['delicate',\n",
       "  'aromas',\n",
       "  'recall',\n",
       "  'white',\n",
       "  'flower',\n",
       "  'and',\n",
       "  'citrus',\n",
       "  'the',\n",
       "  'palate',\n",
       "  'offers',\n",
       "  'passion',\n",
       "  'fruit',\n",
       "  'lime',\n",
       "  'and',\n",
       "  'white',\n",
       "  'peach',\n",
       "  'with',\n",
       "  'a',\n",
       "  'hint',\n",
       "  'of',\n",
       "  'mineral',\n",
       "  'alongside',\n",
       "  'bright',\n",
       "  'acidity']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stop words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from corpus\n",
    "clean_corpus = []\n",
    "\n",
    "for desc in corpus:\n",
    "    desc = [word for word in desc if word not in stop_words]\n",
    "    clean_corpus.append(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset-specific stop words\n",
    "wine_stopwords = ['alongside', 'aroma', 'palate', 'offer', 'hint', 'include', \n",
    "                  'offering', 'recall', 'pretty', 'nose', 'note', 'lightly', \n",
    "                  'part', 'extended', 'series', 'show', 'backed', 'touch', \n",
    "                  'flavor', 'provides', 'companion', 'behind', 'mouthfeel', \n",
    "                  'could', 'plus', 'open', 'background', 'tone', 'stand', \n",
    "                  'isnt', 'expressive', 'mouth', 'wine', 'broad', 'generous', \n",
    "                  'term', 'would', 'make', 'tiny', 'blend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from corpus\n",
    "cleaner_corpus = []\n",
    "\n",
    "for desc in clean_corpus:\n",
    "    desc = [word for word in desc if word not in wine_stopwords]\n",
    "    cleaner_corpus.append(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner_corpus[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejoin lists of words in each description for use in CV & TF-IDF\n",
    "cleaner_corpus_joined = []\n",
    "\n",
    "for doc in cleaner_corpus:\n",
    "    joined = ' '.join(doc)\n",
    "    cleaner_corpus_joined.append(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Then, build model that can determine varietal based on description (use variety as target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ModelSomm: Finally, build model that can determine varietal + Province based off description as a proxy for taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Document-Term Matrix from Wine Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal: come up with most important vocabulary list for wine descriptions (aka distill wine descriptions down to most important parts) --> Figures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()#ngram_range=(1,2))\n",
    "X_cv = cv.fit_transform(cleaner_corpus_joined)\n",
    "\n",
    "print(f\"Dimensions of Document-term matrix: {X_cv.toarray().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checked out the vocab list\n",
    "# cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvec = TfidfVectorizer()#stop_words = 'english')#ngram_range=(1,2))\n",
    "X_tfidf = tfidfvec.fit_transform(clean_corpus_joined)\n",
    "\n",
    "print(f\"Dimensions of Document-term matrix: {X_tfidf.toarray().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PCA for Scree Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing number of components with a scree plot\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200)\n",
    "pca.fit(X_tfidf)\n",
    "pcafeatures_train = pca.transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('# components')\n",
    "plt.ylabel('explained variance');\n",
    "plt.title('Scree plot for digits dataset');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('# components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "plt.title('Cumulative explained variance by PCA for digits');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
