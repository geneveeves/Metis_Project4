{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet') \n",
    "#nltk.download('punkt')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline \n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "sns.set_style(\"white\")\n",
    "sns.set_palette('husl')\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pickled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./clean_wine_data_w_target.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>province</th>\n",
       "      <th>variety</th>\n",
       "      <th>target</th>\n",
       "      <th>target_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aromas include tropical fruit  broom  brimston...</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>White Blend from Sicily &amp; Sardinia</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delicate aromas recall white flower and citrus...</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>White Blend from Sicily &amp; Sardinia</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pretty aromas of yellow flower and stone fruit...</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>White Blend from Sicily &amp; Sardinia</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>part of the extended calanìca series  this gri...</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>White Blend from Sicily &amp; Sardinia</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this offers heady aromas of honeysuckle  white...</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>White Blend from Sicily &amp; Sardinia</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description           province  \\\n",
       "0  aromas include tropical fruit  broom  brimston...  Sicily & Sardinia   \n",
       "1  delicate aromas recall white flower and citrus...  Sicily & Sardinia   \n",
       "2  pretty aromas of yellow flower and stone fruit...  Sicily & Sardinia   \n",
       "3  part of the extended calanìca series  this gri...  Sicily & Sardinia   \n",
       "4  this offers heady aromas of honeysuckle  white...  Sicily & Sardinia   \n",
       "\n",
       "       variety                              target  target_code  \n",
       "0  White Blend  White Blend from Sicily & Sardinia          907  \n",
       "1  White Blend  White Blend from Sicily & Sardinia          907  \n",
       "2  White Blend  White Blend from Sicily & Sardinia          907  \n",
       "3  White Blend  White Blend from Sicily & Sardinia          907  \n",
       "4  White Blend  White Blend from Sicily & Sardinia          907  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial run to create Document-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aacacia</th>\n",
       "      <th>aand</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aas</th>\n",
       "      <th>ab</th>\n",
       "      <th>abacela</th>\n",
       "      <th>abacelas</th>\n",
       "      <th>abadal</th>\n",
       "      <th>abadia</th>\n",
       "      <th>abandon</th>\n",
       "      <th>...</th>\n",
       "      <th>élevé</th>\n",
       "      <th>élévage</th>\n",
       "      <th>émilion</th>\n",
       "      <th>émilions</th>\n",
       "      <th>étoile</th>\n",
       "      <th>über</th>\n",
       "      <th>überaromatic</th>\n",
       "      <th>überbest</th>\n",
       "      <th>ürzig</th>\n",
       "      <th>ürziger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30526 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aacacia  aand  aaron  aas  ab  abacela  abacelas  abadal  abadia  abandon  \\\n",
       "0        0     0      0    0   0        0         0       0       0        0   \n",
       "1        0     0      0    0   0        0         0       0       0        0   \n",
       "2        0     0      0    0   0        0         0       0       0        0   \n",
       "3        0     0      0    0   0        0         0       0       0        0   \n",
       "4        0     0      0    0   0        0         0       0       0        0   \n",
       "\n",
       "   ...  élevé  élévage  émilion  émilions  étoile  über  überaromatic  \\\n",
       "0  ...      0        0        0         0       0     0             0   \n",
       "1  ...      0        0        0         0       0     0             0   \n",
       "2  ...      0        0        0         0       0     0             0   \n",
       "3  ...      0        0        0         0       0     0             0   \n",
       "4  ...      0        0        0         0       0     0             0   \n",
       "\n",
       "   überbest  ürzig  ürziger  \n",
       "0         0      0        0  \n",
       "1         0      0        0  \n",
       "2         0      0        0  \n",
       "3         0      0        0  \n",
       "4         0      0        0  \n",
       "\n",
       "[5 rows x 30526 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a document-term matrix using CountVectorizer\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(df.description)\n",
    "\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = df.index\n",
    "data_dtm.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    " - Way too many features, need to reduce dimensions\n",
    " - Increase list of stop words to target:\n",
    "   - Domain stop words\n",
    "   - Words only used in one review\n",
    "   - Check size of matrix, then potentially remove other most-common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domain Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_stopwords = ['tannins', 'flavors', 'flavor', 'drink', \n",
    "                    'wine', 'finish', 'hints', 'fruit', \n",
    "                    'notes', 'offers', 'aromas', 'style', \n",
    "                    'character', 'hint', 'bit', 'drinkable', \n",
    "                    'palate', 'imported']\n",
    "\n",
    "# Took list of stopwords from a research paper which used the same basic dataset:\n",
    "# Martinez, R., et al.; Grapevine: A Wine Prediction Algorithm Using Multi-dimensional Clustering Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least-Used Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aromas inc'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of all documents\n",
    "corpus = list(df.description)\n",
    "corpus = ' '.join(corpus)\n",
    "corpus[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all words in joined_corpus\n",
    "tokens = [word for word in word_tokenize(corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################## FIX THIS ######################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lemmatize words ---> Need to lemmatize earlier in workflow (maybe in earlier notebook)\n",
    "lemmatized_tokens = [WordNetLemmatizer().lemmatize(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency distribution of words in corpus\n",
    "fdist = FreqDist(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9915"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of words used only once in corpus\n",
    "used_once = fdist.hapaxes()\n",
    "len(used_once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edèlmio',\n",
       " 'baccante',\n",
       " 'setback',\n",
       " 'alastro',\n",
       " 'cavanera',\n",
       " 'bestowed',\n",
       " 'kindness',\n",
       " 'guardian',\n",
       " 'corino',\n",
       " 'cdc',\n",
       " 'rina',\n",
       " 'ianca',\n",
       " 'blanq',\n",
       " 'provoked',\n",
       " 'luncheon',\n",
       " 'albanello',\n",
       " 'donnafranca',\n",
       " 'palas',\n",
       " 'entemari',\n",
       " 'waker',\n",
       " 'impronta',\n",
       " 'phantasmagorical',\n",
       " 'caricante',\n",
       " 'tascas',\n",
       " 'catarrato',\n",
       " 'kue',\n",
       " 'plated',\n",
       " 'cariddi',\n",
       " 'ansonica',\n",
       " 'mon',\n",
       " 'giglio',\n",
       " 'lecrù',\n",
       " 'vv',\n",
       " 'recycle',\n",
       " 'underlaying',\n",
       " 'meandro',\n",
       " 'velhas',\n",
       " 'serodio',\n",
       " 'francescas',\n",
       " 'fonte',\n",
       " 'conceito',\n",
       " 'cambres',\n",
       " 'muxagat',\n",
       " 'assobio',\n",
       " 'fronteira',\n",
       " 'romaneiras',\n",
       " 'pinhao',\n",
       " 'bagos',\n",
       " 'faria',\n",
       " 'serendipitously',\n",
       " 'manzwine',\n",
       " 'càlem',\n",
       " 'redoma',\n",
       " 'edmar',\n",
       " 'redonda',\n",
       " 'murcas',\n",
       " 'altano',\n",
       " 'wheatear',\n",
       " 'espirito',\n",
       " 'prehistoric',\n",
       " 'carla',\n",
       " 'crastos',\n",
       " 'honored',\n",
       " 'rede',\n",
       " 'dodgy',\n",
       " 'menezes',\n",
       " 'montenegro',\n",
       " 'passadouros',\n",
       " 'oriole',\n",
       " 'leda',\n",
       " 'passa',\n",
       " '\\xaddominates',\n",
       " 'barricas',\n",
       " 'rapport',\n",
       " 'sagrado',\n",
       " 'numão',\n",
       " 'vallados',\n",
       " 'recognizing',\n",
       " 'ataíde',\n",
       " 'abilio',\n",
       " 'espoãos',\n",
       " 'virility',\n",
       " 'quay',\n",
       " 'pôpa',\n",
       " 'grandkids',\n",
       " 'pato',\n",
       " 'roca',\n",
       " 'cistus',\n",
       " 'manoella',\n",
       " 'demarcated',\n",
       " 'aciprestes',\n",
       " 'apegadas',\n",
       " 'auru',\n",
       " 'ouro',\n",
       " 'augure',\n",
       " 'esporãos',\n",
       " 'faísca',\n",
       " 'baptista',\n",
       " 'seara',\n",
       " 'dordens',\n",
       " 'reserving',\n",
       " 'stabilization',\n",
       " 'litmus',\n",
       " 'laurelwood',\n",
       " 'renovação',\n",
       " 'charactertistics',\n",
       " 'afoul',\n",
       " 'headlined',\n",
       " 'noseful',\n",
       " 'sbetween',\n",
       " 'oreillys',\n",
       " 'wolfhound',\n",
       " 'pearskin',\n",
       " 'damped',\n",
       " 'elaborating',\n",
       " 'downturn',\n",
       " 'portlandia',\n",
       " 'nominal',\n",
       " 'peaux',\n",
       " 'chalice',\n",
       " 'glug',\n",
       " 'intercede',\n",
       " 'teetered',\n",
       " 'supervalue',\n",
       " 'longish',\n",
       " 'huh',\n",
       " 'staked',\n",
       " 'deadened',\n",
       " 'minimalistic',\n",
       " 'absorbingly',\n",
       " 'girardet',\n",
       " 'irrigate',\n",
       " 'zactly',\n",
       " 'ab',\n",
       " 'ovo',\n",
       " 'surmise',\n",
       " 'unchanging',\n",
       " 'lasciviously',\n",
       " 'eliminating',\n",
       " 'entitled',\n",
       " 'lazily',\n",
       " 'traverse',\n",
       " 'pixy',\n",
       " 'stix',\n",
       " 'okeefe',\n",
       " 'chemically',\n",
       " 'staved',\n",
       " 'weber',\n",
       " 'sims',\n",
       " 'pièce',\n",
       " 'résistance',\n",
       " 'dion',\n",
       " 'beefing',\n",
       " 'worrisome',\n",
       " 'tache',\n",
       " 'heroine',\n",
       " 'giselle',\n",
       " 'courys',\n",
       " 'maxxes',\n",
       " 'retour',\n",
       " 'hefster',\n",
       " 'comfy',\n",
       " 'dreamily',\n",
       " 'excavate',\n",
       " 'tackroom',\n",
       " 'ttb',\n",
       " 'regulation',\n",
       " 'overproduction',\n",
       " 'prerelease',\n",
       " 'encapsulation',\n",
       " 'convene',\n",
       " 'chelans',\n",
       " 'cflavors',\n",
       " 'ombine',\n",
       " 'appassionata',\n",
       " 'lengthened',\n",
       " 'cadeaus',\n",
       " 'equinoxe',\n",
       " 'tardy',\n",
       " 'eldest',\n",
       " 'scrambling',\n",
       " 'camuzet',\n",
       " 'boberg',\n",
       " 'irs',\n",
       " 'antiquum',\n",
       " 'entwines',\n",
       " 'wadensvil',\n",
       " 'tickler',\n",
       " 'playboy',\n",
       " 'vest',\n",
       " 'tahini',\n",
       " 'caffè',\n",
       " 'zena',\n",
       " 'nationally',\n",
       " 'suffocated',\n",
       " 'subtracted',\n",
       " 'tebris',\n",
       " 'wadenswill',\n",
       " 'suzannes',\n",
       " 'seabed',\n",
       " 'nutskins',\n",
       " 'apolloni',\n",
       " 'wildaire',\n",
       " 'monsoon',\n",
       " 'cajoles',\n",
       " 'adjoins',\n",
       " 'pumice',\n",
       " 'desperate',\n",
       " 'honeywood',\n",
       " 'rubarb',\n",
       " 'exaggeration',\n",
       " 'cody',\n",
       " 'webbed',\n",
       " 'springhills',\n",
       " 'goosepen',\n",
       " 'blosser',\n",
       " 'figuratively',\n",
       " 'rippingly',\n",
       " 'pacer',\n",
       " 'flyweight',\n",
       " 'andrus',\n",
       " 'sparky',\n",
       " 'moderating',\n",
       " 'adjoining',\n",
       " 'doozy',\n",
       " 'mutually',\n",
       " 'nuages',\n",
       " 'holstein',\n",
       " 'inhabits',\n",
       " 'configuration',\n",
       " 'skier',\n",
       " 'pricepoint',\n",
       " 'quote',\n",
       " 'aftermath',\n",
       " 'colina',\n",
       " 'caras',\n",
       " 'attaché',\n",
       " 'lableled',\n",
       " 'quatre',\n",
       " 'kahlúa',\n",
       " 'evelyns',\n",
       " 'habanero',\n",
       " 'abetina',\n",
       " 'sunnyside',\n",
       " 'matchup',\n",
       " 'timothy',\n",
       " 'praised',\n",
       " 'altar',\n",
       " 'roosevelt',\n",
       " 'bemoan',\n",
       " 'couse',\n",
       " 'aberrant',\n",
       " 'mystifying',\n",
       " 'aubichons',\n",
       " 'moder',\n",
       " 'diversité',\n",
       " 'verbatim',\n",
       " 'springhill',\n",
       " 'carpe',\n",
       " 'noctum',\n",
       " 'redirected',\n",
       " 'underpriced',\n",
       " 'uniform',\n",
       " 'zivo',\n",
       " 'orginally',\n",
       " 'recovering',\n",
       " 'lux',\n",
       " 'riservata',\n",
       " 'crusade',\n",
       " 'shipped',\n",
       " 'azana',\n",
       " 'corporate',\n",
       " 'plonk',\n",
       " 'blossers',\n",
       " 'mirabai',\n",
       " 'configured',\n",
       " 'tung',\n",
       " 'bieze',\n",
       " 'kalita',\n",
       " 'soonest',\n",
       " 'tracked',\n",
       " 'reustles',\n",
       " 'wondered',\n",
       " 'dutartre',\n",
       " 'slid',\n",
       " 'cursive',\n",
       " 'lettering',\n",
       " 'avellana',\n",
       " 'sentence',\n",
       " 'ambush',\n",
       " 'unsuspecting',\n",
       " 'puller',\n",
       " 'unexpressive',\n",
       " 'amalies',\n",
       " 'keyword',\n",
       " 'bh',\n",
       " 'promoting',\n",
       " 'massale',\n",
       " 'redhawks',\n",
       " 'orchid',\n",
       " 'cited',\n",
       " 'gemini',\n",
       " 'voits',\n",
       " 'ridgecrest',\n",
       " 'sharecropper',\n",
       " 'sod',\n",
       " 'brittans',\n",
       " 'lylee',\n",
       " 'jared',\n",
       " 'bonnie',\n",
       " 'unquestioned',\n",
       " 'édition',\n",
       " 'limitée',\n",
       " 'droppingly',\n",
       " 'horizontally',\n",
       " 'liqueurish',\n",
       " 'richmond',\n",
       " 'shelled',\n",
       " 'mistakenly',\n",
       " 'vault',\n",
       " 'client',\n",
       " 'cagey',\n",
       " 'rumored',\n",
       " 'consolidated',\n",
       " 'jessie',\n",
       " 'gallop',\n",
       " 'someday',\n",
       " 'creole',\n",
       " 'feltz',\n",
       " 'indecipherable',\n",
       " 'deter',\n",
       " 'vinum',\n",
       " 'ferus',\n",
       " 'valour',\n",
       " 'boullion',\n",
       " 'diverting',\n",
       " 'guesstimate',\n",
       " 'sheila',\n",
       " 'quintet',\n",
       " 'coincidently',\n",
       " 'racine',\n",
       " 'earthiest',\n",
       " 'solénas',\n",
       " 'regroups',\n",
       " 'theyd',\n",
       " 'abeyance',\n",
       " 'wwi',\n",
       " 'tuenge',\n",
       " 'barrage',\n",
       " 'kale',\n",
       " 'intractable',\n",
       " 'assigns',\n",
       " 'sumatra',\n",
       " 'definiton',\n",
       " 'jamsheed',\n",
       " 'verified',\n",
       " 'leland',\n",
       " 'campout',\n",
       " 'fakery',\n",
       " 'trickery',\n",
       " 'bottleneck',\n",
       " 'pomengranate',\n",
       " 'spooky',\n",
       " 'orchestration',\n",
       " 'kiana',\n",
       " 'disarmingly',\n",
       " 'resonantly',\n",
       " 'wellspring',\n",
       " 'tagged',\n",
       " 'amalie',\n",
       " 'embarking',\n",
       " 'contraire',\n",
       " 'mortimer',\n",
       " 'aubichon',\n",
       " 'midpriced',\n",
       " 'picnicking',\n",
       " 'parrett',\n",
       " 'abide',\n",
       " 'profundity',\n",
       " 'manipulation',\n",
       " 'delara',\n",
       " 'maysaras',\n",
       " 'speaker',\n",
       " 'fortmiller',\n",
       " 'peeked',\n",
       " 'trumping',\n",
       " 'taunting',\n",
       " 'seemless',\n",
       " 'foo',\n",
       " 'kway',\n",
       " 'insistence',\n",
       " 'balsa',\n",
       " 'undetected',\n",
       " 'jerusalem',\n",
       " 'tangley',\n",
       " 'blackcap',\n",
       " 'doubleback',\n",
       " 'doubling',\n",
       " 'wimp',\n",
       " 'shipping',\n",
       " 'fractured',\n",
       " 'galor',\n",
       " 'effacing',\n",
       " 'popsickle',\n",
       " 'unnameable',\n",
       " 'foreshortening',\n",
       " 'verres',\n",
       " 'duzer',\n",
       " 'pleasureville',\n",
       " 'detrimental',\n",
       " 'stermer',\n",
       " 'compilation',\n",
       " 'unseen',\n",
       " 'crumbling',\n",
       " 'tawniness',\n",
       " 'incude',\n",
       " 'stumbling',\n",
       " 'stevenson',\n",
       " 'assertion',\n",
       " 'giurfo',\n",
       " 'pisciottos',\n",
       " 'marenga',\n",
       " 'shorty',\n",
       " 'crowning',\n",
       " 'calì',\n",
       " 'zabaglione',\n",
       " 'landelin',\n",
       " 'vorbourg',\n",
       " 'tremble',\n",
       " 'kritt',\n",
       " 'untypical',\n",
       " 'quicksand',\n",
       " 'bordered',\n",
       " 'harmoniousness',\n",
       " 'fixture',\n",
       " 'providesthe',\n",
       " 'reappearance',\n",
       " 'zinnkoepflé',\n",
       " 'floss',\n",
       " 'nicety',\n",
       " 'gewuztraminer',\n",
       " 'zinck',\n",
       " 'obernai',\n",
       " 'schoenheitz',\n",
       " 'igentle',\n",
       " 'hugels',\n",
       " 'healing',\n",
       " 'gloried',\n",
       " 'irion',\n",
       " 'sendoff',\n",
       " 'stoeffler',\n",
       " 'eloquent',\n",
       " 'faller',\n",
       " 'weinbach',\n",
       " 'landmann',\n",
       " 'tenderest',\n",
       " 'champignons',\n",
       " 'mettle',\n",
       " 'caramelised',\n",
       " 'conserving',\n",
       " 'spiegel',\n",
       " 'schoenenbourg',\n",
       " 'smouldering',\n",
       " 'tinkling',\n",
       " 'channelled',\n",
       " 'sparr',\n",
       " 'baumanns',\n",
       " 'hohrain',\n",
       " 'hattstatt',\n",
       " 'bierewecke',\n",
       " 'rdevelop',\n",
       " 'sgns',\n",
       " 'generouswine',\n",
       " 'ultrafriendly',\n",
       " 'reckoned',\n",
       " 'wiebelsberg',\n",
       " 'andlau',\n",
       " 'corralling',\n",
       " 'oppose',\n",
       " 'yolk',\n",
       " 'rangen',\n",
       " 'urbain',\n",
       " 'wold',\n",
       " 'adorably',\n",
       " 'softish',\n",
       " 'cep',\n",
       " 'serenely',\n",
       " 'pithier',\n",
       " 'owe',\n",
       " 'blunted',\n",
       " 'pliability',\n",
       " 'letzenberg',\n",
       " 'voegtlinshoffen',\n",
       " 'egremont',\n",
       " 'plumbed',\n",
       " 'funded',\n",
       " 'approacheable',\n",
       " 'jaggy',\n",
       " 'doldrums',\n",
       " 'olie',\n",
       " 'threatened',\n",
       " 'encircled',\n",
       " 'chockful',\n",
       " 'whispered',\n",
       " 'snooze',\n",
       " 'exercised',\n",
       " 'virgorous',\n",
       " 'recession',\n",
       " 'trione',\n",
       " 'mantra',\n",
       " 'tannined',\n",
       " 'glamour',\n",
       " 'extractive',\n",
       " 'hewitt',\n",
       " 'maayan',\n",
       " 'koschitzky',\n",
       " 'sequum',\n",
       " 'artful',\n",
       " 'palmdale',\n",
       " 'crunchier',\n",
       " 'integrative',\n",
       " 'relents',\n",
       " 'maximally',\n",
       " 'compaction',\n",
       " 'lagier',\n",
       " 'bordeauxphiles',\n",
       " 'conquest',\n",
       " 'tamber',\n",
       " 'bey',\n",
       " 'chaise',\n",
       " 'cc',\n",
       " 'sommets',\n",
       " 'apologizing',\n",
       " 'souces',\n",
       " 'fazeli',\n",
       " 'admitting',\n",
       " 'undercurrants',\n",
       " 'crossfire',\n",
       " 'advocacy',\n",
       " 'forging',\n",
       " 'withnapa',\n",
       " 'draught',\n",
       " 'hillview',\n",
       " 'écluse',\n",
       " 'alden',\n",
       " 'gardes',\n",
       " 'veered',\n",
       " 'constituting',\n",
       " 'lewelling',\n",
       " 'zahtila',\n",
       " 'ambassadorial',\n",
       " 'novak',\n",
       " 'dimming',\n",
       " 'beset',\n",
       " 'idyllic',\n",
       " 'shauna',\n",
       " 'lonely',\n",
       " 'populated',\n",
       " 'exoskeleton',\n",
       " 'cary',\n",
       " 'gott',\n",
       " 'foreward',\n",
       " 'overindulgence',\n",
       " 'contrapuntal',\n",
       " 'timely',\n",
       " 'pepperminty',\n",
       " 'xurus',\n",
       " 'strengthening',\n",
       " 'überbest',\n",
       " 'ehret',\n",
       " 'tamely',\n",
       " 'knightsbridge',\n",
       " 'janzen',\n",
       " 'revery',\n",
       " 'aurielles',\n",
       " 'raspberrry',\n",
       " 'monticellos',\n",
       " 'unchilled',\n",
       " 'blowingly',\n",
       " 'temporary',\n",
       " 'lapse',\n",
       " 'thay',\n",
       " 'statistic',\n",
       " 'geologist',\n",
       " 'huerhuero',\n",
       " 'cepages',\n",
       " 'scion',\n",
       " 'kowtow',\n",
       " 'athlete',\n",
       " 'sutter',\n",
       " 'newman',\n",
       " 'pronouncing',\n",
       " 'fragment',\n",
       " 'marston',\n",
       " 'colloquially',\n",
       " 'elu',\n",
       " 'calmly',\n",
       " 'faintness',\n",
       " 'lyman',\n",
       " 'enduiring',\n",
       " 'ollalieberry',\n",
       " 'incoherently',\n",
       " 'maintaing',\n",
       " 'paperwork',\n",
       " 'gushy',\n",
       " 'trimly',\n",
       " 'confronts',\n",
       " 'songwriter',\n",
       " 'featureless',\n",
       " 'peaked',\n",
       " 'crime',\n",
       " 'bluetooth',\n",
       " 'dalle',\n",
       " 'carmènere',\n",
       " 'cirque',\n",
       " 'spectacle',\n",
       " 'hooded',\n",
       " 'scythe',\n",
       " 'tiresome',\n",
       " 'demographic',\n",
       " 'ucd',\n",
       " 'cade',\n",
       " 'inflated',\n",
       " 'montelena',\n",
       " 'drummond',\n",
       " 'topknot',\n",
       " 'ackhurst',\n",
       " 'martial',\n",
       " 'digiulio',\n",
       " 'lyrical',\n",
       " 'demurely',\n",
       " 'overbite',\n",
       " 'freakshow',\n",
       " 'beaulieus',\n",
       " 'sinton',\n",
       " 'konrad',\n",
       " 'hawkeye',\n",
       " 'arisen',\n",
       " 'reluctance',\n",
       " 'slump',\n",
       " 'yao',\n",
       " 'ming',\n",
       " 'hindes',\n",
       " 'rudd',\n",
       " 'lnto',\n",
       " 'macaroni',\n",
       " 'collaborate',\n",
       " 'arid',\n",
       " 'madrigal',\n",
       " 'ple',\n",
       " 'edwardsases',\n",
       " 'overburdened',\n",
       " 'engaged',\n",
       " 'divulges',\n",
       " 'vettas',\n",
       " 'ich',\n",
       " 'tuft',\n",
       " 'addict',\n",
       " 'shrem',\n",
       " 'azalea',\n",
       " 'apportioned',\n",
       " 'dismissed',\n",
       " 'termed',\n",
       " 'wracked',\n",
       " 'gambling',\n",
       " 'wallis',\n",
       " 'weakens',\n",
       " 'klutzy',\n",
       " 'crafton',\n",
       " 'sipability',\n",
       " 'hearken',\n",
       " 'brandlin',\n",
       " 'chewed',\n",
       " 'undermined',\n",
       " 'rash',\n",
       " 'injury',\n",
       " 'horseman',\n",
       " 'wick',\n",
       " 'chocolately',\n",
       " 'counterpoise',\n",
       " 'gateway',\n",
       " 'phrase',\n",
       " 'indescribable',\n",
       " 'oxnard',\n",
       " 'surfboard',\n",
       " 'mushiness',\n",
       " 'miraculously',\n",
       " 'spoto',\n",
       " 'artemis',\n",
       " 'ultracomplex',\n",
       " 'sullenger',\n",
       " 'poundcake',\n",
       " 'olabisi',\n",
       " 'rep',\n",
       " 'gang',\n",
       " 'gristly',\n",
       " 'juggler',\n",
       " 'exhausted',\n",
       " 'laborer',\n",
       " 'remarking',\n",
       " 'tenure',\n",
       " 'albertinas',\n",
       " 'sus',\n",
       " 'triangle',\n",
       " 'flaors',\n",
       " 'imminently',\n",
       " 'poetry',\n",
       " 'moondance',\n",
       " 'aerosmiths',\n",
       " 'overbears',\n",
       " 'sauvig',\n",
       " 'pelissa',\n",
       " 'luxuriate',\n",
       " 'momus',\n",
       " 'gershon',\n",
       " 'bachus',\n",
       " 'frontrunner',\n",
       " 'suiting',\n",
       " 'mountainesque',\n",
       " 'overfilling',\n",
       " 'multiplicity',\n",
       " 'pummel',\n",
       " 'ely',\n",
       " 'prohibit',\n",
       " 'yosemite',\n",
       " 'amicus',\n",
       " 'supérys',\n",
       " 'feb',\n",
       " 'mathematician',\n",
       " 'cb',\n",
       " 'instinct',\n",
       " 'saratoga',\n",
       " 'wealthy',\n",
       " 'darms',\n",
       " 'underbody',\n",
       " 'stomp',\n",
       " 'julio',\n",
       " 'covarrubias',\n",
       " 'enables',\n",
       " 'affection',\n",
       " 'wanders',\n",
       " 'platonic',\n",
       " 'rubenesque',\n",
       " 'spiking',\n",
       " 'lattin',\n",
       " 'cornerback',\n",
       " 'fiercest',\n",
       " 'preponderant',\n",
       " 'battalion',\n",
       " 'andretti',\n",
       " 'conquer',\n",
       " 'finalé',\n",
       " 'noter',\n",
       " 'smoking',\n",
       " 'inkiest',\n",
       " 'unpenetrable',\n",
       " 'scrawling',\n",
       " 'misunderstand',\n",
       " 'celia',\n",
       " 'welch',\n",
       " 'masyczek',\n",
       " 'jammiest',\n",
       " 'tartest',\n",
       " 'flashiness',\n",
       " 'origined',\n",
       " 'outclassed',\n",
       " 'qualified',\n",
       " 'encircling',\n",
       " 'tipped',\n",
       " 'unerring',\n",
       " 'tragedy',\n",
       " 'piñas',\n",
       " 'jake',\n",
       " 'knotts',\n",
       " 'fattiness',\n",
       " 'idol',\n",
       " 'velvetiness',\n",
       " 'foraged',\n",
       " 'jockey',\n",
       " 'niebaums',\n",
       " 'inglenook',\n",
       " 'structuraly',\n",
       " 'overgrown',\n",
       " 'handing',\n",
       " 'oberon',\n",
       " 'wateriness',\n",
       " 'jammily',\n",
       " 'investigate',\n",
       " 'archetype',\n",
       " 'adventurer',\n",
       " 'combustion',\n",
       " 'desiccate',\n",
       " 'gia',\n",
       " 'domella',\n",
       " 'conspicuous',\n",
       " 'phenomenally',\n",
       " 'morlet',\n",
       " 'beautifiul',\n",
       " 'balancedwith',\n",
       " 'olema',\n",
       " 'angst',\n",
       " 'steinhauer',\n",
       " 'bancroft',\n",
       " 'barbour',\n",
       " 'politically',\n",
       " 'drizzed',\n",
       " 'steadfastly',\n",
       " 'loll',\n",
       " 'icarus',\n",
       " 'myth',\n",
       " 'icaria',\n",
       " 'hasa',\n",
       " 'detonating',\n",
       " 'proteinous',\n",
       " 'pip',\n",
       " 'rockaway',\n",
       " 'erin',\n",
       " 'kempe',\n",
       " 'ceiling',\n",
       " 'hendrys',\n",
       " 'modify',\n",
       " 'deceased',\n",
       " 'employee',\n",
       " 'unmelded',\n",
       " 'luxuriates',\n",
       " 'berrries',\n",
       " 'certainty',\n",
       " 'vyborny',\n",
       " 'vaulty',\n",
       " 'erickson',\n",
       " 'participated',\n",
       " 'galleron',\n",
       " 'metalwork',\n",
       " 'swaying',\n",
       " 'romance',\n",
       " 'cdv',\n",
       " 'lambchop',\n",
       " 'flts',\n",
       " 'ponderously',\n",
       " 'protecting',\n",
       " 'perhapstash',\n",
       " 'delectability',\n",
       " 'jessup',\n",
       " 'genetics',\n",
       " 'rosedale',\n",
       " 'upswing',\n",
       " 'drinkabiity',\n",
       " 'sandwiched',\n",
       " 'muscularly',\n",
       " 'brussel',\n",
       " 'sally',\n",
       " 'malibus',\n",
       " 'bogging',\n",
       " 'response',\n",
       " 'til',\n",
       " 'lashed',\n",
       " 'weld',\n",
       " 'dreary',\n",
       " 'sr',\n",
       " 'bialla',\n",
       " 'miner',\n",
       " 'emilios',\n",
       " 'mouthcab',\n",
       " 'stuhlmullers',\n",
       " 'novacaine',\n",
       " 'adornment',\n",
       " 'winfield',\n",
       " 'sconvey',\n",
       " 'coherence',\n",
       " 'sifted',\n",
       " 'pleads',\n",
       " 'mortgage',\n",
       " 'playoff',\n",
       " 'hould',\n",
       " 'béarnaise',\n",
       " 'junction',\n",
       " 'zimmerman',\n",
       " 'tchelistcheffs',\n",
       " 'symbolize',\n",
       " 'helluva',\n",
       " 'endpoint',\n",
       " 'uniformity',\n",
       " 'brochelle',\n",
       " 'netting',\n",
       " 'reichel',\n",
       " 'jd',\n",
       " 'intend',\n",
       " 'disney',\n",
       " 'strove',\n",
       " 'kickboxer',\n",
       " 'interlaces',\n",
       " 'rockrise',\n",
       " 'connotation',\n",
       " 'corisons',\n",
       " 'kronos',\n",
       " 'sinatra',\n",
       " 'crucible',\n",
       " 'slicker',\n",
       " 'stoffer',\n",
       " 'insists',\n",
       " 'goldschmidts',\n",
       " 'tht',\n",
       " 'terrizi',\n",
       " 'giornata',\n",
       " 'oshaughnessy',\n",
       " 'flavorfully',\n",
       " 'mortar',\n",
       " 'salvestrins',\n",
       " 'inebriating',\n",
       " 'kamal',\n",
       " 'navigation',\n",
       " 'swaggering',\n",
       " 'stellareese',\n",
       " 'tumbleweed',\n",
       " 'limousin',\n",
       " 'effected',\n",
       " 'tchelistcheff',\n",
       " 'silencieux',\n",
       " 'clement',\n",
       " 'intensly',\n",
       " 'wurtele',\n",
       " 'dawnine',\n",
       " 'dyer',\n",
       " 'dotting',\n",
       " 'blackberrries',\n",
       " 'err',\n",
       " 'plumed',\n",
       " 'camiana',\n",
       " 'corbett',\n",
       " 'tattered',\n",
       " 'infer',\n",
       " '\\xadworthiness',\n",
       " 'dred',\n",
       " 'valvano',\n",
       " 'steeper',\n",
       " 'sauvignonesque',\n",
       " 'conceptual',\n",
       " 'clutter',\n",
       " 'swordplay',\n",
       " 'signorello',\n",
       " 'cavern',\n",
       " 'fruiter',\n",
       " 'barnetts',\n",
       " 'disturbingly',\n",
       " 'undrinkabiity',\n",
       " 'monumentally',\n",
       " 'lails',\n",
       " 'staglins',\n",
       " 'leathered',\n",
       " 'monovitigno',\n",
       " 'smitten',\n",
       " 'tascante',\n",
       " 'deliveing',\n",
       " 'vajasindi',\n",
       " 'graci',\n",
       " 'magma',\n",
       " 'contrade',\n",
       " 'cornelissens',\n",
       " 'blueish',\n",
       " 'murgo',\n",
       " 'musmeci',\n",
       " 'magnolia',\n",
       " 'fatagione',\n",
       " 'slated',\n",
       " 'ino',\n",
       " 'aomas',\n",
       " 'citrine',\n",
       " 'ty',\n",
       " 'caton',\n",
       " 'scopus',\n",
       " 'lipman',\n",
       " 'tennessee',\n",
       " 'bernal',\n",
       " 'feta',\n",
       " 'unctous',\n",
       " 'ryo',\n",
       " 'fu',\n",
       " 'chenoweths',\n",
       " 'fluttering',\n",
       " 'kisyombe',\n",
       " 'tanzania',\n",
       " 'durells',\n",
       " 'deliciouness',\n",
       " 'laded',\n",
       " 'wamrth',\n",
       " 'nucleus',\n",
       " 'fermention',\n",
       " 'pippigs',\n",
       " 'harm',\n",
       " 'laughlin',\n",
       " 'takahide',\n",
       " 'sugimoto',\n",
       " 'lombardi',\n",
       " 'stilton',\n",
       " 'policy',\n",
       " 'colada',\n",
       " 'killian',\n",
       " 'consisently',\n",
       " 'cellarability',\n",
       " 'dunnings',\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new stop words\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(domain_stopwords, used_once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11183"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This stop words list should cut down on original 30,526-word vocabulary!\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['amaro', 'argues', 'argument', 'assertive', 'bad', 'black', 'blanc', 'blend', 'block', 'bottle', 'bubbly', 'buster', 'cabernet', 'canaiolo', 'chock', 'ciel', 'comb', 'comes', 'day', 'defined', 'dominates', 'edre', 'ele', 'elements', 'especially', 'essential', 'fine', 'ful', 'gance', 'gentle', 'grained', 'graphite', 'grenache', 'honey', 'kiona', 'maca', 'molasses', 'monte', 'mourv', 'oak', 'opening', 'papery', 'power', 'prevail', 'prunes', 'pulciano', 'pushy', 'rhubarb', 'ripe', 'sand', 'sangiovese', 'scented', 'scents', 'sign', 'spice', 'spot', 'straightforward', 'structured', 'surprising', 'syrup', 'sémillon', 'taste', 'tea', 'tempranillo', 'university', 'varieties', 'vineyards', 'worthiness', 'yang', 'years', 'yes', 'ying', 'zinfandel'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aacacia</th>\n",
       "      <th>aaron</th>\n",
       "      <th>abacela</th>\n",
       "      <th>abacelas</th>\n",
       "      <th>abadal</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abate</th>\n",
       "      <th>abbazia</th>\n",
       "      <th>abbey</th>\n",
       "      <th>...</th>\n",
       "      <th>zweigelt</th>\n",
       "      <th>zédé</th>\n",
       "      <th>àmaurice</th>\n",
       "      <th>élevage</th>\n",
       "      <th>élevé</th>\n",
       "      <th>élévage</th>\n",
       "      <th>émilion</th>\n",
       "      <th>émilions</th>\n",
       "      <th>über</th>\n",
       "      <th>ürziger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19731 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aacacia  aaron  abacela  abacelas  abadal  abandon  abandoned  abate  \\\n",
       "0        0      0        0         0       0        0          0      0   \n",
       "1        0      0        0         0       0        0          0      0   \n",
       "2        0      0        0         0       0        0          0      0   \n",
       "3        0      0        0         0       0        0          0      0   \n",
       "4        0      0        0         0       0        0          0      0   \n",
       "\n",
       "   abbazia  abbey  ...  zweigelt  zédé  àmaurice  élevage  élevé  élévage  \\\n",
       "0        0      0  ...         0     0         0        0      0        0   \n",
       "1        0      0  ...         0     0         0        0      0        0   \n",
       "2        0      0  ...         0     0         0        0      0        0   \n",
       "3        0      0  ...         0     0         0        0      0        0   \n",
       "4        0      0  ...         0     0         0        0      0        0   \n",
       "\n",
       "   émilion  émilions  über  ürziger  \n",
       "0        0         0     0        0  \n",
       "1        0         0     0        0  \n",
       "2        0         0     0        0  \n",
       "3        0         0     0        0  \n",
       "4        0         0     0        0  \n",
       "\n",
       "[5 rows x 19731 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a document-term matrix using CountVectorizer\n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "data_cv = cv.fit_transform(df.description)\n",
    "\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = df.index\n",
    "data_dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-db2168b8bb14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtop_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtop_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   2824\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid na_position: {!r}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mna_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2826\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortedIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortedIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;31m# have a proper length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m                         raise ValueError(\n\u001b[1;32m    247\u001b[0m                             \u001b[0;34m'Length of passed values is {val}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Find the words used less than 2 times in descriptions\n",
    "top_dict = {}\n",
    "for c in data.columns:\n",
    "    top = data[c].sort_values(ascending=True).head(100)\n",
    "    top_dict[c]= list(zip(top.index, top.values))\n",
    "\n",
    "top_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top 15 words said by each comedian\n",
    "for comedian, top_words in top_dict.items():\n",
    "    print(comedian)\n",
    "    print(', '.join([word for word, count in top_words[0:14]]))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the least common words used (those used < 2 times) \n",
    "# --> add them to the stop word list\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Let's first pull out the top 30 words for each comedian\n",
    "words = []\n",
    "for comedian in data.columns:\n",
    "    top = [word for (word, count) in top_dict[comedian]]\n",
    "    for t in top:\n",
    "        words.append(t)\n",
    "        \n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's aggregate this list and identify the most common words along with how many routines they occur in\n",
    "Counter(words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If more than half of the comedians have it as a top word, exclude it from the list\n",
    "add_stop_words = [word for word, count in Counter(words).most_common() if count > 6]\n",
    "add_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list of tokenized descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aromas',\n",
       "  'include',\n",
       "  'tropical',\n",
       "  'fruit',\n",
       "  'broom',\n",
       "  'brimstone',\n",
       "  'and',\n",
       "  'dried',\n",
       "  'herb',\n",
       "  'the',\n",
       "  'palate',\n",
       "  'isnt',\n",
       "  'overly',\n",
       "  'expressive',\n",
       "  'offering',\n",
       "  'unripened',\n",
       "  'apple',\n",
       "  'citrus',\n",
       "  'and',\n",
       "  'dried',\n",
       "  'sage',\n",
       "  'alongside',\n",
       "  'brisk',\n",
       "  'acidity'],\n",
       " ['delicate',\n",
       "  'aromas',\n",
       "  'recall',\n",
       "  'white',\n",
       "  'flower',\n",
       "  'and',\n",
       "  'citrus',\n",
       "  'the',\n",
       "  'palate',\n",
       "  'offers',\n",
       "  'passion',\n",
       "  'fruit',\n",
       "  'lime',\n",
       "  'and',\n",
       "  'white',\n",
       "  'peach',\n",
       "  'with',\n",
       "  'a',\n",
       "  'hint',\n",
       "  'of',\n",
       "  'mineral',\n",
       "  'alongside',\n",
       "  'bright',\n",
       "  'acidity']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stop words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from corpus\n",
    "clean_corpus = []\n",
    "\n",
    "for desc in corpus:\n",
    "    desc = [word for word in desc if word not in stop_words]\n",
    "    clean_corpus.append(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset-specific stop words\n",
    "wine_stopwords = ['alongside', 'aroma', 'palate', 'offer', 'hint', 'include', \n",
    "                  'offering', 'recall', 'pretty', 'nose', 'note', 'lightly', \n",
    "                  'part', 'extended', 'series', 'show', 'backed', 'touch', \n",
    "                  'flavor', 'provides', 'companion', 'behind', 'mouthfeel', \n",
    "                  'could', 'plus', 'open', 'background', 'tone', 'stand', \n",
    "                  'isnt', 'expressive', 'mouth', 'wine', 'broad', 'generous', \n",
    "                  'term', 'would', 'make', 'tiny', 'blend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from corpus\n",
    "cleaner_corpus = []\n",
    "\n",
    "for desc in clean_corpus:\n",
    "    desc = [word for word in desc if word not in wine_stopwords]\n",
    "    cleaner_corpus.append(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner_corpus[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejoin lists of words in each description for use in CV & TF-IDF\n",
    "cleaner_corpus_joined = []\n",
    "\n",
    "for doc in cleaner_corpus:\n",
    "    joined = ' '.join(doc)\n",
    "    cleaner_corpus_joined.append(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Then, build model that can determine varietal based on description (use variety as target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ModelSomm: Finally, build model that can determine varietal + Province based off description as a proxy for taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Document-Term Matrix from Wine Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal: come up with most important vocabulary list for wine descriptions (aka distill wine descriptions down to most important parts) --> Figures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()#ngram_range=(1,2))\n",
    "X_cv = cv.fit_transform(cleaner_corpus_joined)\n",
    "\n",
    "print(f\"Dimensions of Document-term matrix: {X_cv.toarray().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checked out the vocab list\n",
    "# cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvec = TfidfVectorizer()#stop_words = 'english')#ngram_range=(1,2))\n",
    "X_tfidf = tfidfvec.fit_transform(clean_corpus_joined)\n",
    "\n",
    "print(f\"Dimensions of Document-term matrix: {X_tfidf.toarray().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PCA for Scree Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing number of components with a scree plot\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200)\n",
    "pca.fit(X_tfidf)\n",
    "pcafeatures_train = pca.transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('# components')\n",
    "plt.ylabel('explained variance');\n",
    "plt.title('Scree plot for digits dataset');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('# components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "plt.title('Cumulative explained variance by PCA for digits');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
